{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read input from pickle\n",
    "# turn them into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "name='msd_data1.pickle'\n",
    "infile=open(name,'rb')\n",
    "data=pickle.load(infile)\n",
    "infile.close()\n",
    "Y_train=np.array(data['Y_train'])\n",
    "X_train=np.array(data['X_train'])\n",
    "Y_test=np.array(data['Y_test'])\n",
    "X_test=np.array(data['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standarlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean=np.mean(X_train, axis=0)\n",
    "std=np.std(X_train, axis=0)\n",
    "X_train_norm=X_train.copy()\n",
    "X_test_norm=X_test.copy()\n",
    "X_train_norm=(X_train_norm-mean)/std\n",
    "X_test_norm=(X_test_norm-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  53.39967   56.67781   55.63508 ...    1.3159     2.37448    1.85999]\n",
      " [  42.83464  -33.90478   38.97704 ...    9.72827 -175.51446  -15.8389 ]\n",
      " [  49.88591   23.30563   54.79012 ...    1.94152  101.27241    8.99355]\n",
      " ...\n",
      " [  41.04397  -96.30727   56.8073  ...    3.60251  -97.24809   -5.80797]\n",
      " [  42.8676    43.36365   29.17957 ...   18.71014  208.9029   -11.08426]\n",
      " [  36.57558   29.8733    -3.08101 ...   21.0417   106.60317    3.44396]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62556548  1.05564491  1.33908654 ... -0.22192259 -0.1087769\n",
      "   0.03568937]\n",
      " [-0.09558527 -0.68108552  0.86818824 ...  0.40727698 -1.12403384\n",
      "  -0.78882859]\n",
      " [ 1.05313827  0.41580362  1.31520077 ... -0.17512961  0.45565848\n",
      "   0.36801238]\n",
      " ...\n",
      " [-0.38730362 -1.87752187  1.37222348 ... -0.05089658 -0.67734797\n",
      "  -0.32152912]\n",
      " [-0.09021576  0.80037392  0.59122816 ...  1.07907205  1.06993276\n",
      "  -0.56732961]\n",
      " [-1.11524976  0.54172487 -0.32073102 ...  1.25346007  0.48608246\n",
      "   0.10947997]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一題 [myknn_regressor]\n",
    "# Q1.1 \n",
    "# Create your myknn_regressor.\n",
    "\n",
    "# 將index和distance存在一個list of list\n",
    "# 再用sort取第二個值去比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take(x):\n",
    "    return x[1]\n",
    "class myknn_regressor:\n",
    "    def __init__(self, k, option):\n",
    "        self.k=k\n",
    "        self.option=option\n",
    "        self.xtrain=[]\n",
    "        self.ytrain=[]\n",
    "    def fit(self, x, y):\n",
    "        self.xtrain=x\n",
    "        self.ytrain=y\n",
    "    def predict(self, xtest):\n",
    "        ypred=np.zeros((len(xtest),))\n",
    "        for i in range(len(xtest)):#each test case\n",
    "            dist=[]#index+distance\n",
    "            for j in range(len(self.xtrain)):\n",
    "                temp=(xtest[i]-self.xtrain[j])**(2)\n",
    "                dist.append([j,np.sum(temp)])\n",
    "            dist.sort(key=take)\n",
    "            top=[]\n",
    "            for j in range(self.k):\n",
    "                ypred[i]+=self.ytrain[dist[j][0]]/self.k\n",
    "                top.append(self.ytrain[dist[j][0]])\n",
    "            if self.option=='remove_outliers' and self.k>=10:\n",
    "                top.sort()\n",
    "                q1=self.k*0.25\n",
    "                if q1 % 1 ==0:\n",
    "                    q1=int(q1)\n",
    "                    q1=(top[q1]+top[q1-1])/2\n",
    "                else:\n",
    "                    q1=top[int(q1)]\n",
    "                q3=self.k*0.75\n",
    "                if q3 % 1 ==0:\n",
    "                    q3=int(q3)\n",
    "                    q3=(top[q3]+top[q3-1])/2\n",
    "                else:\n",
    "                    q3=top[int(q3)]\n",
    "                iqr=q3-q1\n",
    "                low=q1-1.5*iqr\n",
    "                high=q3+1.5*iqr\n",
    "                ya=[]\n",
    "                for x in top:\n",
    "                    if x>low and x<high:\n",
    "                        ya.append(x.copy())\n",
    "                ya=np.array(ya)\n",
    "                ypred[i]=np.mean(ya)\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(ypred, y):\n",
    "    return np.sqrt(np.mean((ypred-y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1.2 \n",
    "# Predictions using k=20 and \"equal_weight\" f\n",
    "# List the RMSE and the first 20 predictions in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1993.35 1993.8  2000.65 1991.5  1992.8  1998.5  1988.1  1991.65 2002.25\n",
      " 2003.   2000.5  1998.65 1995.55 1997.2  1995.05 1997.4  1992.15 2000.45\n",
      " 2003.2  1995.75]\n",
      "10.25126451549596\n"
     ]
    }
   ],
   "source": [
    "myknn = myknn_regressor(20, \"equal_weight\")\n",
    "myknn.fit(X_train_norm, Y_train)\n",
    "ypred = myknn.predict(X_test_norm)\n",
    "performance=rmse(ypred,Y_test)\n",
    "print(ypred[:20])\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q1.3\n",
    "# Predictions using k=20 and \"remove_outier\" f\n",
    "# List the RMSE and the first 20 predictions in the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1993.35       1993.8        2000.65       1991.5        1992.8\n",
      " 2000.         1988.1        1991.65       2002.25       2003.94736842\n",
      " 2000.5        2000.94444444 1995.55       1997.2        1998.61111111\n",
      " 1997.4        1992.15       2003.83333333 2003.2        1995.75      ]\n",
      "10.230096835631896\n"
     ]
    }
   ],
   "source": [
    "myknn = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn.fit(X_train_norm, Y_train)\n",
    "ypred = myknn.predict(X_test_norm)\n",
    "performance=rmse(ypred,Y_test)\n",
    "print(ypred[:20])\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第二題 [Tuning the Hyper-parameter]\n",
    "# case1: knn with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.911074724837043\n",
      "12.068170946750795\n",
      "11.389120864846157\n",
      "11.1123354880961\n",
      "10.894692897614565\n",
      "10.425998912973919\n",
      "10.318171959828572\n",
      "10.25126451549596\n",
      "10.23762722509469\n",
      "10.215977156359507\n",
      "10.205243203546763\n",
      "10.204332770527754\n",
      "10.207243171822855\n",
      "10.206033712139762\n",
      "10.208862384446808\n",
      "10.21700262724764\n",
      "10.231954198429056\n",
      "10.247295947386965\n",
      "10.264908458982783\n",
      "10.287098382403647\n",
      "10.317788599090449\n",
      "10.330995620176944\n",
      "10.351940397014143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "ks=[1,2,3,4,5,10,15,20,25,30,35,40,45,50,55,60,80,100,120,140,160,180,200]\n",
    "rmses_norm=[]\n",
    "for k in ks:\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train_norm, Y_train)\n",
    "    knnn=neigh.predict(X_test_norm)\n",
    "    performance=rmse(knnn,Y_test)\n",
    "    rmses_norm.append(performance)\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# case2: knn without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.923638966418345\n",
      "12.777499755429464\n",
      "12.075674967716129\n",
      "11.767805657810635\n",
      "11.466392632384432\n",
      "11.07746090040493\n",
      "10.888979137947995\n",
      "10.797788546734928\n",
      "10.79007301797969\n",
      "10.75026561256701\n",
      "10.717738719772289\n",
      "10.714437504678756\n",
      "10.698494013475852\n",
      "10.69110105960404\n",
      "10.682608734124413\n",
      "10.672535729098724\n",
      "10.662907517124493\n",
      "10.67701950452466\n",
      "10.683139638996407\n",
      "10.687017556442052\n",
      "10.691630026202155\n",
      "10.69071978380711\n",
      "10.698853374700175\n"
     ]
    }
   ],
   "source": [
    "rmses=[]\n",
    "for k in ks:\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k)\n",
    "    neigh.fit(X_train, Y_train)\n",
    "    knn=neigh.predict(X_test)\n",
    "    performance=rmse(knn,Y_test)\n",
    "    rmses.append(performance)\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# case3: myknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1999. 1994. 2000. ... 2008. 2008. 2001.]\n",
      "13.911074724837043\n",
      "[2003.  1990.  2002.  ... 2003.  2008.  2001.5]\n",
      "12.068170946750795\n",
      "[2003.66666667 1988.33333333 2000.66666667 ... 2001.66666667 2007.66666667\n",
      " 1997.33333333]\n",
      "11.389120864846157\n",
      "[2003.25 1988.75 1999.5  ... 2001.25 2007.5  1994.75]\n",
      "11.1123354880961\n",
      "[2000.6 1990.8 2000.4 ... 2002.2 2007.8 1994.4]\n",
      "10.894692897614568\n",
      "[2002.375 1992.3   1999.2   ... 1995.4   2006.5   1994.7  ]\n",
      "10.451153139459992\n",
      "[1996.         1992.2        2000.26666667 ... 2002.16666667 2006.30769231\n",
      " 1993.53333333]\n",
      "10.277581670823931\n",
      "[1993.35       1993.8        2000.65       ... 2002.94117647 2002.6\n",
      " 1994.25      ]\n",
      "10.230096835631896\n",
      "[1995.69565217 1995.2        2001.28       ... 2001.52380952 2002.68\n",
      " 1994.24      ]\n",
      "10.19065614155901\n",
      "[1992.93333333 1995.53333333 2001.26666667 ... 1996.46666667 2002.68965517\n",
      " 1993.9       ]\n",
      "10.138961714632806\n",
      "[1993.11428571 1995.65714286 2001.34285714 ... 1998.72727273 2002.88235294\n",
      " 1993.91428571]\n",
      "10.103831894869057\n",
      "[1992.3        1995.425      2001.38461538 ... 1999.62162162 2003.07692308\n",
      " 1994.125     ]\n",
      "10.090495875400158\n",
      "[1992.57777778 1996.06666667 2001.5952381  ... 1998.46511628 2003.25581395\n",
      " 1994.26666667]\n",
      "10.081790023728978\n",
      "[1991.8        1995.52       2001.         ... 1998.20833333 2003.125\n",
      " 1994.02      ]\n",
      "10.084583890206702\n",
      "[1992.63636364 1996.30909091 2001.08       ... 1997.09090909 2002.77358491\n",
      " 1994.34545455]\n",
      "10.06157509545477\n",
      "[1992.23333333 1996.6779661  2000.94545455 ... 1997.74576271 2002.98275862\n",
      " 1994.71666667]\n",
      "10.082145231152138\n",
      "[1993.2625     1997.11392405 2000.8630137  ... 1997.84810127 2002.74025974\n",
      " 1995.6       ]\n",
      "10.063521103942389\n",
      "[1993.68       1997.34343434 2000.67741935 ... 1998.98958333 2002.40206186\n",
      " 1995.04      ]\n",
      "10.064946233489977\n",
      "[1994.15       1996.79661017 2000.59459459 ... 1999.46956522 2002.88034188\n",
      " 1995.46666667]\n",
      "10.06838310523937\n",
      "[1994.44604317 1996.85507246 2000.4453125  ... 1999.97727273 2002.56296296\n",
      " 1995.74285714]\n",
      "10.08838135430302\n",
      "[1994.90506329 1997.25316456 1999.12337662 ... 2000.02631579 2001.99354839\n",
      " 1995.75      ]\n",
      "10.110516492257728\n",
      "[1994.16666667 1997.28248588 1998.6091954  ... 2000.03529412 2002.34302326\n",
      " 1996.07222222]\n",
      "10.126588512624334\n",
      "[1995.18781726 1996.82914573 1998.82901554 ... 1999.88888889 2002.28795812\n",
      " 1996.125     ]\n",
      "10.144119404326311\n"
     ]
    }
   ],
   "source": [
    "my_rmses=[]\n",
    "for k in ks:\n",
    "    myknn = myknn_regressor(k, \"remove_outliers\")\n",
    "    myknn.fit(X_train_norm, Y_train)\n",
    "    ypred = myknn.predict(X_test_norm)\n",
    "    print(ypred)\n",
    "    performance=rmse(ypred,Y_test)\n",
    "    my_rmses.append(performance)\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the curves\n",
    "# relations between  k(x-axis) and RMSE (y-axis)\n",
    "# red: knn without normalization\n",
    "# blue: knn with normalization\n",
    "# greeen: my knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ks, rmses_norm, 'b')\n",
    "plt.plot(ks, rmses, 'r')\n",
    "plt.plot(ks, my_rmses, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "結果討論：\n",
    "\n",
    "有normalize過的knn表現都比較好，因為normalize後將feature的影響力變得一樣，\n",
    "譬如要預測性別，有個feature是身高，有個feature是體重，這兩個單位和數值不一樣，\n",
    "直接拿來計算，會讓一公分跟一公斤的影響力一樣，而實際上不一定如此，\n",
    "所以普遍來說normalize過後的表比較好。\n",
    "\n",
    "可能也會有normalize後表現變差的情形，我推論可能是數值較大的剛好是影響力較大的feature，\n",
    "剛好放大了這個feature的影響力，符合這個特定資料的特性，所以放原本資料的表現還比較好。\n",
    "\n",
    "自己實作的knn表現比套件好，可能是因為remove oulier的效果，讓預測不受離群值影響，所以準確率提高。\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
